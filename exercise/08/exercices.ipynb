{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f26dc3c",
   "metadata": {},
   "source": [
    "<font size=\"5\"><b>Lecture 08: Machine Learning 2/3 (exercises)</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293ce49e",
   "metadata": {},
   "source": [
    "# EX: Semantic classification of satellite image (part 1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b39ac0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>This exercice has been developped by <u>Andreas Ley</u> and <u>Ronny Hänsch</u> (TU-Berlin) in the framework of the GEO.X 2017 Autumn school.<br>\n",
    "<br>\n",
    "The exercice is designed to implement the classification of a satellite image (Sentinel-2) into semantic labels defining land use: forest, fields, urban, water.<br>\n",
    "<br>\n",
    "The exercice is split into 2 parts: this first part (lecture 08) will implement a PCA analisis on the image crops in order to reduce dimensionality. The second part (lecture 09) will use the outputs of the PCA and implement a SVM to classify the pixels into different land use classes.\n",
    "    </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4245b95f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b><u>Description of the dataset</u></b>:<br>\n",
    "<br>\n",
    "The data stored in the file \"images/s2_training_data.npz\" contains image crops of a Sentinel-2 multispectral image, and some semantic labels of land use.<br>\n",
    "    <br>\n",
    "    The file can be loaded using <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.load.html?highlight=load#numpy.load\" target=\"_blank\">numpy.load()</a>, and contains 2 parts:<br>\n",
    "    <ul>\n",
    "        <li><u>data</u>: contains 20,000 patches (crops), each of 15x15 pixels and 4 channels (R + G + B + shortwave-infrared). The data is organized as one numpy array of shape (20000, 4, 15, 15), where the first dimension are the instances, the next dimension are the channels, and the latter two are width and height.<br> The first 5000 crops contain forest in the central pixel, the next 5000 contain fields/lower vegetation, the next 5000 are urban areas, and the last 5000 are water.</li>\n",
    "        <li><u>labels</u>: contains semantic labels of land use (forest, fields, urban, water), which will be later used for training the classifier. These can be ignored for now.</li>\n",
    "    </ul>   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53f6bd9",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edfc932",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Load the data using numpy.load(). Store the \"data\" in a variable named \"train_X\", anf the \"labels\" in a variable named \"train_Y\". Explore the shape of these arrays.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129cc7b7",
   "metadata": {},
   "source": [
    "## inspect image crops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d2ecbb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Use the function below to look at the (RGB-part) of individual crops.<br>Take a look at the first crop of each class (remember: crops 1-5k contain forest, crops 5-10k contain fields, crops 10-15k are urban areas, and crops 15-20k are water).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d022ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_raw_image(img):\n",
    "    img2 = np.log(img[[2,1,0],:,:])\n",
    "\n",
    "    img2[0,:,:] = img2[0,:,:].copy() * 1.05303 + -6.32792\n",
    "    img2[1,:,:] = img2[1,:,:].copy() * 1.74001 + -10.8407\n",
    "    img2[2,:,:] = img2[2,:,:].copy() * 1.20697 + -6.73016\n",
    "\n",
    "    img2 = np.clip(img2 / 6 + 0.5, 0.0, 1.0)\n",
    "\n",
    "    plt.imshow(np.transpose(img2, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1554b444",
   "metadata": {},
   "source": [
    "## compress image crops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641ebd7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    The data train_X contains the raw values which span a large range. To compress them into a more “gaussian” shape, compute the logarithm of them.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d35f2f",
   "metadata": {},
   "source": [
    "## build function to compute principal components of image crops\n",
    "The following tasks will implement a function \"compute_mean_PCs(X)\" which takes image crops as inputs, and returns the mean image, Eigen images (principal components reshaped into images), and Eigen values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80e0262",
   "metadata": {},
   "source": [
    "### compute mean crop, and mean-free crops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e619613c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Compute the mean image crop, and name the resulting array \"mean\".<br>\n",
    "    Subtract this \"mean\" from all crops, and name the resulting array \"mean_free\".<br>\n",
    "    <br>\n",
    "    Hint: The mean image should be an array of shape (4, 15, 15), and the mean free crops should be an array of shape (20000, 4, 15, 15)).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7139ca",
   "metadata": {},
   "source": [
    "### vectorize the mean-free crops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078bb76d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Flatten the crops into vectors so that you get a numpy array of shape (20000, 4 * 15 * 15).<br>\n",
    "    <br>\n",
    "    Hint: use \"np.reshape\".\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff74a35",
   "metadata": {},
   "source": [
    "### compute the covariance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20a778f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Compute the covariance matrix. This should be a matrix of size 900x900 (900 = 4 * 15 * 15).<br>\n",
    "    <br>\n",
    "    Start by defining a matrix of zeros with shape (900,900). Loop over all 20000 crops, and for each crop compute the outer product <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.outer.html?highlight=outer#numpy.outer\" target=\"_blank\">np.outer(u, v)</a> of the mean-free vector with itself (i.e., u = v = vectorized crop). Accumulate (sum) the outer products together and finally divide by the total number of used crops. (To speed up development, consider using only every 10th crop).<br>\n",
    "    <br>\n",
    "    NB: the <a href=\"https://en.wikipedia.org/wiki/Outer_product\" target=\"_blank\">outer product</a> $u \\otimes v$ is equivalent to a matrix multiplication $u \\cdot v^T$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b082f8",
   "metadata": {},
   "source": [
    "### compute Eigen values & Eigen vectors of the covariance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c31e2eb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Compute the Eigen values \"eig_val\" and Eigen vectors \"eig_vec\" of the covariance matrix using <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.linalg.eig.html?highlight=eig#numpy.linalg.eig\" target=\"_blank\">np.linalg.eig()</a>.<br>\n",
    "    <br>\n",
    "    Sort them by importance (decreasing Eigen values) using the following code:<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168ccf91",
   "metadata": {},
   "source": [
    "```python\n",
    "# Sort by importance\n",
    "idx = np.argsort(eig_val)[::-1]\n",
    "eig_vec = eig_vec[:,idx]\n",
    "eig_val = eig_val[idx]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aece929",
   "metadata": {},
   "source": [
    "### reshape Eigen vectors into Eigen images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0d7029",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Reshape the 900 eigen vectors back into the images, i.e. with shape (900, 4, 15, 15), and name this variable \"principal_components\".<br>\n",
    "    <br>\n",
    "    Note that the matrix eig_vec contains the Eigen vectors in its rows (not columns as you might expect), so you'll need to transpose the matrix before reshaping it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba8535a",
   "metadata": {},
   "source": [
    "### merge into function \"compute_mean_PCs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac0f4dd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Merge steps 1.4.1 to 1.4.4 into a single function \"compute_mean_PCs\".<br>\n",
    "    <br>\n",
    "    The function will take the image crops as inputs (i.e., variable \"train_X\"), and will return the mean image (i.e., variable \"mean\"), the Eigen images (principal components reshaped into images, i.e., variable \"principal_components\"), and Eigen values (i.e., variable \"eig_val\").\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86748cc8",
   "metadata": {},
   "source": [
    "## run \"compute_mean_PCs\" and plot Eigen values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e67493a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Run \"compute_mean_PCs\" on the satellite data, and plot the returned Eigen values.<br>\n",
    "    <br>\n",
    "    Look at the first 64 principal components (or the RGB part thereof) using the following function:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feede195",
   "metadata": {},
   "source": [
    "```python\n",
    "def show_first_principal_components(pcs):\n",
    "\n",
    "    f, axarr = plt.subplots(8,8)\n",
    "    for i in range(0,8):\n",
    "        for j in range(0,8):\n",
    "            img2 = pcs[i*8+j, [2,1,0], :, :]\n",
    "            img2 = np.clip(img2 * 10 + 0.5, 0.0, 1.0)\n",
    "            axarr[i,j].imshow(np.transpose(img2, (1, 2, 0)))\n",
    "\n",
    "    plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89895a96",
   "metadata": {},
   "source": [
    "## compute features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2fdd6b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Write a function \"compute_features(X, mean, principal_components, count)\" that takes crops \"X\", subtracts the mean, and projects them onto the first \"count\" principal components.<br>\n",
    "    <br>\n",
    "    The returned array should have a shape (X.shape[0], count), containing the coefficients (which we will use as features in next week's exercise).<br>\n",
    "    <br>\n",
    "    Hint: the projection is done using the dot product.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c6581b",
   "metadata": {},
   "source": [
    "## reconstruct image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d7791a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Write a function \"reconstruct_image(feature, mean, principal_components)\" that restores a crop given a feature/coefficient vector.<br>\n",
    "    <br>\n",
    "    Use the following code to compare, side by side, original image crops and reconstructions:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f39070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to compare, side by side, original image crops and reconstructions: \n",
    "for i in range(0,4):    \n",
    "    img = np.concatenate((train_X[5000*i+0,:,:,:], reconstruct_image(train_features[5000*i+0,:], mean, principal_components)), 2);\n",
    "    img = np.concatenate((img,np.concatenate((train_X[5000*i+1,:,:,:], reconstruct_image(train_features[5000*i+1,:], mean, principal_components)), 2)), 1);\n",
    "    img = np.concatenate((img,np.concatenate((train_X[5000*i+2,:,:,:], reconstruct_image(train_features[5000*i+2,:], mean, principal_components)), 2)), 1);\n",
    "    img = np.concatenate((img,np.concatenate((train_X[5000*i+3,:,:,:], reconstruct_image(train_features[5000*i+3,:], mean, principal_components)), 2)), 1);\n",
    "    img = np.concatenate((img,np.concatenate((train_X[5000*i+4,:,:,:], reconstruct_image(train_features[5000*i+4,:], mean, principal_components)), 2)), 1);\n",
    "    show_raw_image(np.exp(img))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
