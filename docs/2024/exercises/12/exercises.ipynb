{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"><b>Lecture 12: Deep Learning DL2 (exercises)</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d76b57",
   "metadata": {},
   "source": [
    "**HOW TO RUN THIS NOTEBOOK**:<br>\n",
    "\n",
    "1.   <u>if TF installed locally</u><br>\n",
    "⇒ activate the conda environment in which you installed Tensor Flow (e.g., \"tf\"), and launch jupyter & this notebook from it:<br>\n",
    "```\n",
    "$ conda activate tf\n",
    "$ jupyter notebook\n",
    "```\n",
    "2.   <u>if using GoogleColab</u><br>\n",
    "⇒ simply open this notebook<br>\n",
    "NB: the TensorBoard notebook extension can be loaded from GoogleColab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA BENE**: some exercices are inspired by Aurélien Géron's book _\"Hands-on Machine Learning with Scikit-Learn, Keras & TensorFlow\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5abe018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN from scratch (MNIST fashion dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    In this exercice, you will design and train <b>Convolutional Neural Network (CNN)</b> classify the MNIST-fashion dataset, just as you did with the <b>MLP</b> model.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Load the MNIST fashion dataset.<br>\n",
    "    Split the full training dataset (images and labels) to have create a validation dataset of 5000 instances.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Preprocess the datasets:<br>\n",
    "    1. compute the mean and standard deviation of the training dataset<br>\n",
    "    2. scale the datasets (training, validation and test): on each dataset, substract the mean value, and divide by the standard deviation<br>\n",
    "    3. add a dimension to each dataset array (so keras will know it is dealing with a single color channel image, i.e. grayscale)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build model (using the Sequential API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Build a CNN with the following architecture.<br>\n",
    "    Carefully look at the model. Explain the overall architecture (can you identify blocks?), and explain what each layer does.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\", input_shape=[28, 28, 1]),\n",
    "    tf.keras.layers.MaxPooling2D(2),\n",
    "    tf.keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.MaxPooling2D(2),\n",
    "    tf.keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.MaxPooling2D(2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Compile the model with the following settings:<br>\n",
    "    <ul>\n",
    "        <li>loss=\"sparse_categorical_crossentropy\"</li>\n",
    "        <li>optimizer=\"nadam\"</li>\n",
    "        <li>metrics=[\"accuracy\"]</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Train your model on the training dataset during 10 epochs, and use the validation dataset to evaluate while training. Use a batch_size of 32 images.<br>\n",
    "    <br>\n",
    "    Before launching the .fit() function, create a tensorboard callback using the code below. Place it in a list, and pass it to the .fit() using the \"callbacks\"option.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    Depending on your hardware, the training might be very slow. In order to speed-up the exercice, we will upload the weigths of a trained model. Go to the last section of this exercice, and follow the steps to restore the trained model.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_dir = \"log/cnn_deep/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## view training progression using Tensor Board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Use Tensor Board in order to visualize the training progression.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e2ee91",
   "metadata": {},
   "source": [
    "### if running notebook from Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62d5aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension IN GOOGLE COLAB\n",
    "# NB: need to wait for first epoch to complete in order to start visualizing time series!\n",
    "# IMPORTANT: click refresh button once 1 epoch achieved\n",
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir log/cnn_deep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3b117e",
   "metadata": {},
   "source": [
    "### if running notebook from local installation\n",
    "Open a terminal and type:\n",
    "```\n",
    "$ conda activate tf\n",
    "$ cd <working dir>\n",
    "$ tensorboard --logdir log/cnn_deep    # set directory used to store logs\n",
    "```\n",
    "Open a web-browser at the address:\n",
    "```\n",
    "http://localhost:6006/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31f7b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension IN GOOGLE COLAB\n",
    "# NB: need to wait for first epoch to complete in order to start visualizing time series!\n",
    "# IMPORTANT: click refresh button once 1 epoch achieved\n",
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir log/cnn_deep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Evaluate the model on the test dataset. What is the score?<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Take 10 images from the test dataset (pretending we have new images!), and predict the class. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save/upload trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/keras/save_and_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- save trained model (weights)\n",
    "# Use the following line of code to save the weights once you are happy with your trained model.\n",
    "\n",
    "model.save_weights('./checkpoints/my_checkpoint') # directory will be automatically created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- restore model\n",
    "# Use the following lines of code to restore a trained model from the saved weights.\n",
    "\n",
    "# - Create a new model instance\n",
    "# NB: ideally you should create a function to avoid re-writting it the model!\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\", input_shape=[28, 28, 1]),\n",
    "    tf.keras.layers.MaxPooling2D(2),\n",
    "    tf.keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.MaxPooling2D(2),\n",
    "    tf.keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.MaxPooling2D(2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# - Restore the weights\n",
    "model.load_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# - Compile\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning: fine-tune a pre-trained CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Desining and training your own network can be difficult (or impossible if you do not have enough data).<br>\n",
    "    <br>\n",
    "    It has therefore become common practice to do \"<u>transfer learning</u>\": reuse the lower layers of a pretrained model, and fine-tune the upper layers of a model designed to achieve your task.<br>\n",
    "    <br>\n",
    "    In this exercice, you will train a model to classify pictures of flowers, reusing the pretrained <u>Xception model</u>. This exercice is a guided \"copy-paste\" rather than actual programming!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## install tensorflow-datasets (tfds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    The TensorFlow DataSets (TFDS) project makes it very easy to download common datasets of various types (see complete list <a href=\"https://www.tensorflow.org/datasets/catalog/overview#all_datasets\" target=\"_blank\">here</a>).<br>\n",
    "    <br>\n",
    "    TFDS is not bundled with TensorFlow, so you need to install the <u>tensorflow-datasets</u> library. If it is not yet installed in your conda environment, follow the steps below:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ conda activate tf\n",
    "$ conda install -c anaconda tensorflow-datasets\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Load the dataset \"tf_flowers\" from the tensorflow_datasets using the code below. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "import tensorflow_datasets as tfds\n",
    "dataset, info = tfds.load(\"tf_flowers\", as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = info.splits[\"train\"].num_examples\n",
    "class_names = info.features[\"label\"].names\n",
    "n_classes = info.features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(info.splits)\n",
    "print(dataset_size)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Use the TFDS library to split the dataset into \"test\" (first 10%), \"validate\" (10-25%) and \"test\" (remaining 75%).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_set_raw, valid_set_raw, train_set_raw), metadata = tfds.load(\n",
    "    'tf_flowers',\n",
    "    split=[\n",
    "       tfds.Split.TRAIN.subsplit(tfds.percent[:10]),\n",
    "       tfds.Split.TRAIN.subsplit(tfds.percent[10:25]),\n",
    "       tfds.Split.TRAIN.subsplit(tfds.percent[25:])\n",
    "    ],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the raw dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "index = 0\n",
    "for image, label in train_set_raw.take(9):\n",
    "    index += 1\n",
    "    plt.subplot(3, 3, index)\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Class: {}\".format(class_names[label]))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    The preprained CNN we want to use is the <u>Xception</u> model. In order to use it, we need to preprocess our images as the CNN expects them:<br>\n",
    "    <ul>\n",
    "        <li>Xception expects 224x224 images</li>\n",
    "        <li>Xception expects images parsed through it's preprocess_input() function</li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    We can therefore define the following preprocess() function to fill these two expectations. Next, apply this preprocessing function to all three datasets, shuffle the training set, and add batching and prefetching to all the datasets.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    resized_image = tf.image.resize(image, [224, 224])\n",
    "    final_image = tf.keras.applications.xception.preprocess_input(resized_image)\n",
    "    return final_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_set = train_set_raw.shuffle(1000)\n",
    "train_set = train_set_raw.map(preprocess).batch(batch_size).prefetch(1)\n",
    "valid_set = valid_set_raw.map(preprocess).batch(batch_size).prefetch(1)\n",
    "test_set = test_set_raw.map(preprocess).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_set_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data augmentation (optional) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    In case your dataset is very limited, you can perform some data augmentation to in order to virtually increase the amount of data for training.<br>\n",
    "    Below are some examples of data augmentation techniques, using image cropping and flipping.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Aurélien Géron\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "def central_crop(image):\n",
    "    shape = tf.shape(image)\n",
    "    min_dim = tf.reduce_min([shape[0], shape[1]])\n",
    "    top_crop = (shape[0] - min_dim) // 4\n",
    "    bottom_crop = shape[0] - top_crop\n",
    "    left_crop = (shape[1] - min_dim) // 4\n",
    "    right_crop = shape[1] - left_crop\n",
    "    return image[top_crop:bottom_crop, left_crop:right_crop]\n",
    "\n",
    "def random_crop(image):\n",
    "    shape = tf.shape(image)\n",
    "    min_dim = tf.reduce_min([shape[0], shape[1]]) * 90 // 100\n",
    "    return tf.image.random_crop(image, [min_dim, min_dim, 3])\n",
    "\n",
    "def preprocess(image, label, randomize=False):\n",
    "    if randomize:\n",
    "        cropped_image = random_crop(image)\n",
    "        cropped_image = tf.image.random_flip_left_right(cropped_image)\n",
    "    else:\n",
    "        cropped_image = central_crop(image)\n",
    "    resized_image = tf.image.resize(cropped_image, [224, 224])\n",
    "    final_image = tf.keras.applications.xception.preprocess_input(resized_image)\n",
    "    return final_image, label\n",
    "\n",
    "batch_size = 32\n",
    "train_set = train_set_raw.shuffle(1000).repeat()\n",
    "train_set = train_set.map(partial(preprocess, randomize=True)).batch(batch_size).prefetch(1)\n",
    "valid_set = valid_set_raw.map(preprocess).batch(batch_size).prefetch(1)\n",
    "test_set = test_set_raw.map(preprocess).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: these basic data augmentation functions are implemented in keras!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load pretrained CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    You can download the Xception model, which we will use as the base of our model.<br>\n",
    "    <br>\n",
    "    Use the following settings:\n",
    "    <ul>\n",
    "        <li>weights=\"imagenet\": this will download the weigths learned while training on the ImageNet dataset</li>\n",
    "        <li>include_top=False: this will exclude the top of the network, i.e. the <i>global average pooling layer</i> and the <i>dense output layer</i> of the model</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - load Xception model and define as base model\n",
    "base_model = tf.keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    We now need to add layers to our model, which we need to actually perform on our own cassification task:<br>\n",
    "    <ul>\n",
    "        <li>a <i>global average pooling layer</i>, based on the output of the base model</li>\n",
    "        <li>a <i>dense output layer</i> with one unit per class, using the softmax activation function</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: include_top=False removes in case we did not want a Global Average Pooling layer; it turns out we want it, so we add it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - add layers for our training\n",
    "avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output) # takes base_model ouputs as input\n",
    "output = tf.keras.layers.Dense(n_classes, activation=\"softmax\")(avg) # takes GlobalAveragePooling2D layer as input\n",
    "\n",
    "# - create final model\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to freeze the weights of the pre-trained layers at the beginning of training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers: #OOP !\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - compile\n",
    "optimizer = tf.keras.optimizers.SGD(lr=0.2, momentum=0.9, decay=0.01)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - train\n",
    "history = model.fit(train_set, epochs=5, validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fine-tuning: unfreeze all layers and continue training\n",
    "After training the model for a few epochs, the validation accuracy should reach about 75–80% and stop making much progress.<br>\n",
    "<br>\n",
    "This means that the top layers are now pretty well trained, so we are ready to unfreeze all the layers (or just the top ones) and continue training: we are now <u>FINE TUNING</u> the pretrained weigths.<br>\n",
    "<br>\n",
    "Important: In order to avoid damaging what the base layers have learned on the ImageNet dataset (i.e. pretrained weights), we need to use a much lower learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - unfreeze base layers\n",
    "for layer in base_model.layers: #NB: could iterate on only a part of these layers\n",
    "    layer.trainable = True\n",
    "\n",
    "# - set much lower learning rate to avoid damaging the pretrained weights\n",
    "optimizer = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - recompile and continue training\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, epochs=5, validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d789d3d",
   "metadata": {},
   "source": [
    "# MLP (MNIST fashion dataset): Tensor Board and python script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88744e1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    During the previous lecture (Deep Learning 1), you designed/trained a <b>Multi Layered Perceptron (MLP)</b> network (i.e. a fully connected artificial neural network ANN) to classify the MNIST fashion dataset.<br>\n",
    "    <br>\n",
    "    This exercise is meant to show you how you can use a Python script to design the network (often more convenient than Jupyter notebooks!), and visualize the training using Tensor Board interface.\n",
    "    <br>\n",
    "    <br>\n",
    "    <u>Note</u>: in the previous exercise we implemented a fairly deep network with several convolutional layers. The Python script \"tf_mnist-fashion_cnn.py\" implements a shallower CNN, in order to have a better comparison of the performance one can achieve with a MLP and CNN (i.e. compare accuracy, number of parameters, etc.).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7172ecad",
   "metadata": {},
   "source": [
    "## run the python script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7922cc1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Open a terminal, activate your conda environment, and launch the Python script \"tf_mnist-fashion_mlp.py\" as follows:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffffbc52",
   "metadata": {},
   "source": [
    "```\n",
    "$ conda activate tf\n",
    "$ cd <working dir>\n",
    "$ python tf_mnist-fashion_mlp.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b94d6ce",
   "metadata": {},
   "source": [
    "## view training progression using Tensor Board"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b9dfd6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Use Tensor Board in order to visualize the training progression.<br>\n",
    "    <br>\n",
    "    To do so, follow the steps described below:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691ba0b7",
   "metadata": {},
   "source": [
    "```\n",
    "Open terminal launch TensorBoard from your working environment:\n",
    "$ conda activate tf\n",
    "$ cd <working dir>\n",
    "$ tensorboard --logdir log/mlp    # set directory used to store logs, as defined in the Python script\n",
    "\n",
    "Open a web-browser at the address:\n",
    "http://localhost:6006/\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "292.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
